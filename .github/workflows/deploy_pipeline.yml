name: CI

on:
  push:
    branches:
      - main
      - dev

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      DBFS_LIB_PATH: dbfs:/sql_files/
      REPO_PATH: /Repos/Development

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8

      - name: Install dependencies
        run: |
          pip install databricks-cli
          pip install pytest setuptools wheel

      - name: Configure Databricks CLI
        run: |
          mkdir -p ~/.databricks
          echo -e "[DEFAULT]\nhost = ${{ secrets.DATABRICKS_HOST }}\ntoken = ${{ secrets.DATABRICKS_TOKEN }}" > ~/.databricks/config

      - name: Extract branch name
        id: extract_branch
        run: echo "branch=$(echo ${GITHUB_REF#refs/heads/})" >> $GITHUB_ENV

      - name: Update Databricks Git folder
        run: |
          databricks repos update --path ${{ env.REPO_PATH }} --branch "${{ env.branch }}"

      - name: Prepare SQL files
        run: |
          mkdir -p sql_files
          cp projects/pipe1/*.sql sql_files/
          cp projects/pipe2/*.sql sql_files/

      - name: Debug - List files
        run: |
          echo "Listing SQL files in sql_files directory:"
          ls -alh sql_files

      - name: Upload SQL files to Databricks
        run: |
          files=$(ls sql_files)
          for file in $files; do
            echo "Uploading file: $file"
            databricks fs cp --overwrite sql_files/$file ${{ env.DBFS_LIB_PATH }}$file
          done

      - name: Run pipeline script
        env:
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DBFS_LIB_PATH: ${{ env.DBFS_LIB_PATH }}
        run: |
          python main.py
