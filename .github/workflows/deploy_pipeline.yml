name: Deploy Delta Live Tables Pipeline

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      DBFS_LIB_PATH: dbfs:/sql_files
      REPO_PATH: /Repos/Development

      
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: pip install requests
             pip install databricks-cli
        
      - name: Extract branch name
        shell: bash
        run: echo "##[set-output name=branch;]$(echo ${GITHUB_REF#refs/heads/})"
        id: extract_branch

      - name: Update Databricks Git folder
        run: |
          databricks repos update --path ${{env.REPO_PATH}}â€‚ --branch "${{ steps.extract_branch.outputs.branch }}"

      - name: Build Wheel and send to Databricks workspace DBFS location
        run: |
          cd $GITHUB_WORKSPACE
          python setup.py bdist_wheel
          dbfs cp --overwrite ./dist/* ${{env.DBFS_LIB_PATH}}
          
      - name: Prepare SQL files
        run: |
          mkdir -p sql_files
          cp projects/pipe1/*.sql sql_files/
          cp projects/pipe2/*.sql sql_files/

      - name: Upload SQL files to Databricks
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          files=$(ls sql_files)
          for file in $files; do
            curl -n \
              -F path="/dbfs/sql_files/$file" \
              -F contents=@sql_files/$file \
              -H "Authorization: Bearer $DATABRICKS_TOKEN" \
              -X POST https://$DATABRICKS_HOST/api/2.0/dbfs/put
          done

      - name: Run pipeline script
        env:
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          BASE_PATH: "sql_files"
        run: |
          python main.py



          